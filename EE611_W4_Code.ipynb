{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem Statement:**\n",
    "\n",
    "**Objective:** Train a feed-forward neural network using data from the “Appliances Energy Prediction Dataset” and predict the appliance energy consumption for specific dates.\n",
    "\n",
    "**Note:** The dataset used for this exercise comes from measurements taken from a low-energy home in Stambruges, Belgium, for 5 months (January to May 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un-comment and run the below cell to check list of libraries installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un-comment and run the below cell to install tensorflow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexes for specific date_times (Do not change these)\n",
    "\n",
    "index_Jan19_18 = 1160-2\n",
    "index_Mar12_8 = 8732-2\n",
    "index_May15_12 = 17972-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to extract data from file, Load training data and convert into Numpy array\n",
    "\n",
    "def get_data(file_name,test_fraction=0.2):\n",
    "    df_input = pd.read_csv(file_name,\n",
    "                           usecols=['lights','T1','RH_1','T2','RH_2','T3','RH_3','T_out','Hour']) #you can modify this - 'RH_out','T3', 'T4','Visibility','Tdewpoint','Day_of_week'\n",
    "    \n",
    "    df_target = pd.read_csv(file_name, \n",
    "                            usecols=['Appliances'])\n",
    "    \n",
    "    print(df_input.head())       #Print first few columns of input data\n",
    "    print(df_target.head())      #Print first few columns of target data\n",
    "    \n",
    "    X_data = df_input.values\n",
    "    y_data = df_target.values\n",
    "    \n",
    "    X_data.astype('float32', copy=False)\n",
    "    y_data.astype('float32', copy=False)\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_data, \n",
    "                                                          y_data, \n",
    "                                                          test_size=test_fraction)  #function to split data set\n",
    "    \n",
    "    return X_data, y_data, X_train, y_train, X_valid, y_valid # Return training, test data as arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "\n",
    "# TO-DO:\n",
    "# Adjust the parameters: L1, L2,and L3; also the t_fraction based on the values given in the Instruction Document.\n",
    "\n",
    "L1 = 10 # Number of neurons in Layer 1 (You can change this)\n",
    "L2 = 5 # Number of neurons in Layer 2 (You can change this)\n",
    "L3 = 10 # Number of neurons in Layer 3 (You can change this)\n",
    "\n",
    "# Data set\n",
    "t_fraction = 0.4 # Fraction of data set used for validation (You can change this)\n",
    "\n",
    "### END YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data\n",
    "\n",
    "file_name = './EE611_W4_Dataset.csv' #NOTE: Change this Path only if the Dataset is in different directory\n",
    "\n",
    "X_data, y_data, X_train, y_train, X_valid, y_valid = get_data(file_name,\n",
    "                                                         test_fraction = t_fraction)\n",
    "\n",
    "print('Shape of training input data set: ', X_train.shape)\n",
    "print('Shape of training target data set: ', y_train.shape)\n",
    "print('Number of training samples: ', len(X_train))\n",
    "print('Shape of validation input data set: ',X_valid.shape)\n",
    "print('Shape of validation target data set: ',y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "\n",
    "epochs = 10           # Number of times to peform training (you can change this)\n",
    "display_epoch = 2  \n",
    "learning_rate = 0.01  # The rate at which weights are updated in the neural network\n",
    "mini_batch_size = 32  # The size to which the training data is split up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholders for input and output\n",
    "\n",
    "Xfeatures = X_train.shape[1]  # Number of features in input data\n",
    "Yfeatures = 1                 # Number of features in target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "\n",
    "# TO-DO:\n",
    "# Comment/Un-comment the Layers (i.e Layer1, Layer2, Layer3) in the Neural network \n",
    "# based on the values given in the Instruction Document.\n",
    "\n",
    "# Building and training a single layer model using Keras\n",
    "# Reference Link about keras - https://www.tensorflow.org/guide/keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#Input Layer\n",
    "model.add(keras.layers.InputLayer(input_shape=(Xfeatures,),\n",
    "                                  name='InputLayer'))\n",
    "\n",
    "#Normalization Layer\n",
    "model.add(keras.layers.BatchNormalization(axis=1))  #Normalizing values\n",
    "\n",
    "# Layer1\n",
    "model.add(keras.layers.Dense(units=L1,\n",
    "                             activation='relu',\n",
    "                             bias_initializer='zeros',\n",
    "                             name='FeedForward1'))  #Add a feed forward layer\n",
    "\n",
    "# Layer2 \n",
    "# model.add(keras.layers.Dense(units=L2,\n",
    "#                              activation='relu',\n",
    "#                              name='FeedForward2'))  #Add a feed forward layer\n",
    "\n",
    "# Layer3 \n",
    "# model.add(keras.layers.Dense(units=L3,\n",
    "#                              activation='relu',\n",
    "#                              name='FeedForward3'))  #Add a feed forward layer\n",
    "\n",
    "#Output layer \n",
    "model.add(keras.layers.Dense(units=Yfeatures,\n",
    "                             name='OutputLayer'))\n",
    "\n",
    "#Specify loss function and optimizer\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae'])\n",
    "\n",
    "#Summarize model\n",
    "model.summary()\n",
    "\n",
    "### END YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to train model\n",
    "#Start Training model\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=mini_batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_valid,y_valid),\n",
    "          shuffle =True,\n",
    "          verbose=2)\n",
    "\n",
    "model.save('energy_pred.keras')\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIONAL ###\n",
    "### START YOUR CODE HERE ###\n",
    "\n",
    "prediction = model.predict(X_valid)       #Find predicted value on random data set\n",
    "\n",
    "### END YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIONAL ###\n",
    "### START YOUR CODE HERE ###\n",
    "# This uses Tensorflow Library to calculate MAE Score\n",
    "# To know more about MAE check the below links -  \n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/metrics/mean_absolute_error\n",
    "# https://www.educative.io/answers/mean-absolute-error-in-sklearn\n",
    "\n",
    "mae = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae(y_valid, prediction).numpy())\n",
    "\n",
    "### END YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIONAL ###\n",
    "### START YOUR CODE HERE ### \n",
    "# This uses sklearn Library to calculate MAE Score (Uncomment if you need to use sklearn)\n",
    "\n",
    "# from sklearn import metrics\n",
    "\n",
    "# mae = metrics.mean_absolute_error(y_valid, prediction)\n",
    "# print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "\n",
    "### END YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Inference session\n",
    "\n",
    "index = random.randint(0, len(X_valid))                     #Find random input vector from dataset\n",
    "prediction_rand = model.predict(X_valid, batch_size=1)      #Find predicted value on random data set\n",
    "\n",
    "\n",
    "print(\"Predicted load for input vector {} is {} Wh\".format(X_valid[index], *prediction_rand[0]))\n",
    "\n",
    "print(\"Actual appliance load is {} Wh and Absolute Error is {}\".format(y_valid[index][0], \n",
    "                                                                       abs(prediction_rand[0]-y_valid[index])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "\n",
    "# TO-DO:\n",
    "# Comment/Un-comment the input data corresponding to the dates for which predictions are required \n",
    "# based on the values given in the Instruction document.\n",
    "\n",
    "#Input data for January 19, 18:00, 2016 (Uncomment below lines if this is the date you want)\n",
    "X_date = np.resize(X_data[index_Jan19_18], (1, Xfeatures))\n",
    "index = index_Jan19_18\n",
    "\n",
    "#Input data for March 12, 8:00, 2016 (Uncomment below lines if this is the date you want)\n",
    "#X_date = np.resize(X_data[index_Mar12_8],(1,Xfeatures))\n",
    "#index = index_Mar12_8  \n",
    "\n",
    "#Input data for May 12, 12:00, 2016 (Uncomment below lines if this is the date you want)\n",
    "# X_date = np.resize(X_data[index_May15_12],(1, Xfeatures) )\n",
    "# index = index_May15_12\n",
    "\n",
    "### END YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "\n",
    "# TO-DO: \n",
    "# 1. Get the prediction value from the first print statement(i.e) *prediction[0] for the corresponding parameters and date\n",
    "# 2. Get the Absolute Error value from the second print statement(i.e) [abs(prediction[0]-y_data[index])[0])]\n",
    "# Get the above values and populate them for corresponding row in the Tables.\n",
    "\n",
    "# Predict for selected date\n",
    "\n",
    "prediction = model.predict(X_date, batch_size=1)\n",
    "\n",
    "\n",
    "print(\"Predicted load for input vector {} is {} Wh\".format(X_date[0], *prediction[0]))\n",
    "\n",
    "print(\"Actual appliance load is {} Wh and Absolute Error is {}\".format(y_data[index][0],\n",
    "                                                                       abs(prediction[0]-y_data[index])[0]))\n",
    "\n",
    "### END YOUR CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
